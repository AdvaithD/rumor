external_ip="$(curl -s v4.ident.me)"
p2p_port=9030

echo "External IP used in ENRs: $external_ip"

enr make \
  --ip="$external_ip" \
  --tcp=$p2p_port \
  --udp=$p2p_port \
  --attnets="0xffffffffffffffff" \
  --fork-digest="0xfdca39b0" \
  --next-fork-version="0x00000121" \
  --next-fork-epoch="0xffffffffffffffff"




# create a shared peerstore, we can hook more actors to it later.
peerstore create crawler

# Try and get 400 peers connected, because why not, we're a crawler.
# And tag, see how many users identify us
host start --lo-peers=400 --hi-peers=500 --peer-grace-period=30s --agent="Crawly McCrawlface"
host listen --tcp=$p2p_port --udp=$p2p_port --ip=0.0.0.0

# Set up a fake Altona status
include fake_status.rumor

# Set up malicious endpoints, never actually sync
rpc blocks-by-range listen --drop
rpc blocks-by-root listen --drop
rpc goodbye listen --drop

# Start polling status of everyone
# Exchange status with everyone every slot
peer status poll --interval=12s  --timeout=3s

# Ping everyone, and update metadata if they have new data for us
peer metadata poll --interval=30s  --timeout=10s  --update=true --update-timeout=20s

# Serve pong requests, also update if we get a higher ping than known
peer metadata pong --update=true

## Start discv5, and keep querying random nodes
#dv5 run
## Add whatever we see to the peerstore
#dv5 random --add --filter-digest="0xfdca39b0"
#
#while 1; do
#  host peer list all
#  all_peers=$__peers
#  echo "Still crawling, got ${#all_peers[@]} peers"
#
##  for peer_id in "${all_peers[@]}"; do
##    echo "key  : $peer_id"
##    peer info $peer_id
##  done
#
#  sleep 20s
#done
